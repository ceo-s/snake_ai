1. Тема, описание задачи
   Reinforsment learning agent to play snake game

2. База (если нет конфиденциальных данных)
   Нет

3. Параметризация данных
   Было опробовано: - подавать чб изображение, сжатое до пикселей - вектор с информацией о дистанции до стен и цели, направлением и наличием опасности вокруг головы - бинарный вектор с информацией о направлении, наличии опасности (слева, спереда, справа), координатах цели (лево, верх, право, низ)

4. Архитектура нейросети
   Попробовал генетику и классичекую DQN модель.

5. Графическое подтверждение (графики обучения…)
   ![plots]()

6. Ноутбук (или .py файл)
   GA - _[]()_
   DQN - _[q_snake_keras.ipynb]()_, _[q_snake_keras_train.py]()_

7. Выводы
   Бинарный вектор - самый слабый способ параметризаци из опробованных, но пока что DQN научилась работать только на нём.
   Это проблема, так как это слишком слабый инпут для того чтобы прогрессировать дальше.
   Генетика работала на векторе с дистанцией, что посильнее бинарного вектора, но она так и не смогла дойти до нормальных результатов, хотя в целом полученная ГА модель очень хорошо видела первые 3-4 цели.

Сейчас за рабочую можно считать только DQN модель, но для лучших результатов нужно будет что-то менять.

8. План дальнейшей работы
   Поэкспереминтирую с входными векторами, а если ничего не получится, то буду делать модель сильнее и подавать целиком изображение.
